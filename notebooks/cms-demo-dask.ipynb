{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc22f81-737d-4187-860a-68b11b744fb5",
   "metadata": {},
   "source": [
    "# Using local and remote DASK on CMS Data\n",
    "\n",
    "CMS datasets tend to be quite large. We should be able to use DASK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a6ee3a-86cf-4f51-abe1-2254f36cb1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_adl_servicex import ServiceXSourceCMSRun1AOD\n",
    "from servicex.servicex import ServiceXDataset\n",
    "from coffea.processor.servicex import Analysis, DataSource, LocalExecutor, DaskExecutor\n",
    "from func_adl import ObjectStream\n",
    "from hist import Hist\n",
    "\n",
    "import asyncio\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016886c0-a77e-4c98-b687-987703db4e6a",
   "metadata": {},
   "source": [
    "## Defining the base query\n",
    "\n",
    "* We are using the CMS Run 1 AOD file type here\n",
    "* No global event cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bda4e26-5e39-406e-93f1-33046e7c330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ServiceXSourceCMSRun1AOD('cernopendata://dummy')\n",
    "ds.return_qastle = True  # Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82448bc0-e02e-419a-93ab-d4ae42cf9613",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting Clean Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6aa0dd6-8e60-417b-b319-d379942f2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "leptons_source = (\n",
    "    ds\n",
    "    .Select(lambda e: {\n",
    "        \"m\": e.Muons(\"muons\"),\n",
    "        \"e\": e.GsfElectrons(\"gsfElectrons\"), \n",
    "        \"p\": e.Vertex(\"offlinePrimaryVertices\")[0].position()\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad79f719-0a22-4d46-b302-d1b9194e2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_leptons = (\n",
    "     leptons_source\n",
    "     .Select(lambda i: {\n",
    "          \"m\": i.m\n",
    "               .Where(lambda m: m.isPFMuon()\n",
    "                         and m.isPFIsolationValid()\n",
    "                         and isNonnull(m.globalTrack())\n",
    "                         and abs(sqrt((m.globalTrack().dxy(i.p) * m.globalTrack().dxy(i.p))\n",
    "                                   + (m.globalTrack().dz(i.p) * m.globalTrack().dz(i.p)))\n",
    "                              / sqrt((m.globalTrack().d0Error() * m.globalTrack().d0Error())\n",
    "                                        + (m.globalTrack().dzError() * m.globalTrack().dzError()))) < 4.0\n",
    "                         and abs((m.globalTrack()).dxy(i.p)) < 0.5\n",
    "                         and abs((m.globalTrack()).dz(i.p)) < 1.\n",
    "                         and ((m.pfIsolationR04()).sumChargedHadronPt\n",
    "                              + (m.pfIsolationR04()).sumNeutralHadronEt\n",
    "                              + (m.pfIsolationR04()).sumPhotonEt) / m.pt() < 0.4\n",
    "                         and m.pt() > 5.\n",
    "                         and abs(m.eta()) < 2.4\n",
    "               ),\n",
    "          \"e\": i.e\n",
    "               .Where(lambda e: e.passingPflowPreselection()\n",
    "                         and e.pt() > 7.\n",
    "                         and abs(e.superCluster().eta()) < 2.5\n",
    "                         and e.gsfTrack().trackerExpectedHitsInner().numberOfHits() <= 1\n",
    "                         and abs(sqrt((e.gsfTrack().dxy(i.p) * e.gsfTrack().dxy(i.p))\n",
    "                                   + (e.gsfTrack().dz(i.p) * e.gsfTrack().dz(i.p)))\n",
    "                              / sqrt((e.gsfTrack().d0Error() * e.gsfTrack().d0Error())\n",
    "                                        + (e.gsfTrack().dzError() * e.gsfTrack().dzError()))) < 4.\n",
    "                         and abs(e.gsfTrack().dxy(i.p)) < 0.5 and abs(e.gsfTrack().dz(i.p)) < 1.\n",
    "                         and (e.isEB() or e.isEE())\n",
    "                         and (e.pfIsolationVariables().chargedHadronIso\n",
    "                              + e.pfIsolationVariables().neutralHadronIso\n",
    "                              + e.pfIsolationVariables().photonIso) / e.pt() < 0.4\n",
    "                         )\n",
    "     })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53cfbb-602f-400e-9144-5bef2572b5e1",
   "metadata": {},
   "source": [
    "And pull out the columns we need for selection in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a88be73-be15-440a-bfc5-d4cc3a80ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms_selection = (\n",
    "    data_leptons\n",
    "    .Select(lambda i: (\n",
    "        i.m.Select(lambda m: m.pt()),\n",
    "        i.m.Select(lambda m: m.phi()),\n",
    "        i.m.Select(lambda m: m.eta()),\n",
    "        i.m.Select(lambda m: m.energy()),\n",
    "        i.m.Select(lambda m: m.charge()),\n",
    "        i.e.Select(lambda m: m.pt()),\n",
    "        i.e.Select(lambda m: m.phi()),\n",
    "        i.e.Select(lambda m: m.eta()),\n",
    "        i.e.Select(lambda m: m.energy()),\n",
    "        i.e.Select(lambda m: m.charge()),\n",
    "    ))\n",
    "    .AsROOTTTree('file.root', 'treeme', columns = [\n",
    "        'mu_pt', 'mu_phi', 'mu_eta', 'mu_energy', 'mu_charge',\n",
    "        'el_pt', 'el_phi', 'el_eta', 'el_energy', 'el_charge',\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df477b-c580-4f87-93a7-de7d7083f378",
   "metadata": {},
   "source": [
    "## Performing the Analysis\n",
    "\n",
    "We are re-using, almost line-for-line, the work of an IRIS-HEP 2021 fellow, Brian Cruz, there. He developed a notebook that run on nano-aod's, and then converted the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad1ffdf-1b4d-4c80-a661-fd495512b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMS_Higgs_4L(Analysis):\n",
    "    '''Run the 4 Lepton analysis on CMS open data Run 1 AOD's\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def process(events):\n",
    "        from collections import defaultdict\n",
    "        import awkward as ak\n",
    "        import numpy as np\n",
    "        import numpy as np\n",
    "\n",
    "        import awkward as ak\n",
    "\n",
    "        sumw = defaultdict(float)\n",
    "        mass_hist = (Hist.new\n",
    "                     .Reg(60, 60, 180, name='mass', label='$m_{4\\ell}$ [GeV]')\n",
    "                     .StrCat([], name='dataset', label='Cut Type', growth=True)\n",
    "                     .StrCat([], name='channel', label='Channel', growth=True)\n",
    "                     .Int64()\n",
    "                    )\n",
    "\n",
    "        dataset = events.metadata['dataset']\n",
    "        \n",
    "        good_mu = events.mu\n",
    "        good_e = events.el\n",
    "\n",
    "        # This code is copied directly from Brian Cruz's CMS Notebook that\n",
    "        # uses the converted nano-aod's\n",
    "        \n",
    "        # function that finds the best combination of pairs with a mass closest to the real Z mass\n",
    "        mZ = 91.1876\n",
    "        def closest(pair):\n",
    "            delta = abs(mZ - pair.mass[:])\n",
    "            closest_masses = np.min(delta, axis=-1)\n",
    "            the_closest = (delta == closest_masses)\n",
    "            return the_closest\n",
    "        \n",
    "        ### Higgs to 4 muons ###\n",
    "        \n",
    "        # entries with 4 muons\n",
    "        mu4 = good_mu[ak.num(good_mu) >= 4]\n",
    "\n",
    "        if len(mu4) > 0:\n",
    "\n",
    "            # sort the events from highest to lowest transverse momentum\n",
    "            mu4_sorted = mu4[ak.argsort(mu4.pt, axis=-1, ascending=False)]\n",
    "\n",
    "            # select the first 4 muons from the sorted mu4\n",
    "            f4_mu4_sorted = mu4_sorted[:,0:4]\n",
    "\n",
    "            # select the 4 muons with a zero net charge\n",
    "            f4c0_mu4_sorted = f4_mu4_sorted[ak.sum(f4_mu4_sorted[:,:,\"charge\"], axis=-1) == 0]\n",
    "\n",
    "            # creating muon pairs\n",
    "            muon_pair = ak.combinations(f4c0_mu4_sorted, 2)\n",
    "\n",
    "            # combinations with zero net charge\n",
    "            muon_pair_c0 = muon_pair[(muon_pair[\"0\"].charge + muon_pair[\"1\"].charge)==0]\n",
    "\n",
    "            # get the closest Z boson (Za) and farthest Z boson (Zb)\n",
    "            Z_muons = (muon_pair_c0[\"0\"] + muon_pair_c0[\"1\"])\n",
    "            Za_muons = closest(Z_muons)\n",
    "            Zb_muons = Za_muons[:,::-1]\n",
    "\n",
    "            # best combination of muons\n",
    "            Za_2mu = muon_pair_c0[Za_muons]\n",
    "            Zb_2mu = muon_pair_c0[Zb_muons]\n",
    "\n",
    "            # flatten the arrays\n",
    "            Za_mu = ak.flatten(Za_2mu)\n",
    "            Zb_mu = ak.flatten(Zb_2mu)\n",
    "\n",
    "            # Mass requirement \n",
    "            M_Za_mu = (((Za_mu[\"0\"]+Za_mu[\"1\"]).mass>40)&((Za_mu[\"0\"]+Za_mu[\"1\"]).mass<120))\n",
    "            M_Zb_mu = (((Zb_mu[\"0\"]+Zb_mu[\"1\"]).mass>12)&((Zb_mu[\"0\"]+Zb_mu[\"1\"]).mass<120))\n",
    "\n",
    "            # Transverse momentum requirement\n",
    "            pt_Z_mu = (Za_mu[\"0\"].pt>20)&(Za_mu[\"1\"].pt>10)\n",
    "\n",
    "            # applying the cuts to get the good Z bosons\n",
    "            good_Za_mu = Za_mu[pt_Z_mu&M_Za_mu&M_Zb_mu]\n",
    "            good_Zb_mu = Zb_mu[pt_Z_mu&M_Za_mu&M_Zb_mu]\n",
    "\n",
    "            # adding the Z boson pairs (Higgs decay to 4 muons calculation)\n",
    "            higgs4mu = good_Za_mu['0']+good_Za_mu['1'] + good_Zb_mu['0']+good_Zb_mu['1']\n",
    "\n",
    "            # applying a mass range\n",
    "            Higgs_4mu = higgs4mu[higgs4mu.mass>70]\n",
    "\n",
    "            mass_hist.fill(\n",
    "                mass=Higgs_4mu.mass,\n",
    "                channel='4mu',\n",
    "                dataset=dataset\n",
    "            )\n",
    "        \n",
    "        ### Higgs to 4 muons ends ###\n",
    "\n",
    "        ### Higgs to 4 electrons starts ###\n",
    "\n",
    "        # entries with four electrons\n",
    "        e4 = good_e[ ak.num(good_e)>=4 ]\n",
    "        \n",
    "        if len(e4) > 0:\n",
    "\n",
    "            # sorting the events from high to low transverse momentum\n",
    "            e4_sorted = e4[ak.argsort(e4.pt, axis=-1, ascending=False)]\n",
    "\n",
    "            # selecting the first 4 electrons from the sorted e4\n",
    "            f4_e4_sorted = e4_sorted[:,0:4]\n",
    "\n",
    "            # selecting the 4 electrons with a zero net charge\n",
    "            f4c0_e4_sorted = f4_e4_sorted[ ak.sum(f4_e4_sorted[:,:,\"charge\"], axis=-1)==0 ]\n",
    "\n",
    "            # creating electron pairs\n",
    "            e_pair = ak.combinations(f4c0_e4_sorted, 2)\n",
    "\n",
    "            # combinations with zero net charge\n",
    "            e_pair_c0 = e_pair[ (e_pair[\"0\"].charge + e_pair[\"1\"].charge)==0 ]\n",
    "\n",
    "            # get the closest Z boson (Za) and farthest Z boson (Zb)\n",
    "            Z_electrons = ( e_pair_c0[\"0\"] + e_pair_c0[\"1\"] )\n",
    "            Za_electrons = closest(Z_electrons)\n",
    "            Zb_electrons = Za_electrons[:,::-1]\n",
    "\n",
    "            # best combination of electrons\n",
    "            Za_2e = e_pair_c0[Za_electrons]\n",
    "            Zb_2e = e_pair_c0[Zb_electrons]\n",
    "\n",
    "            # flatten the arrays\n",
    "            Za_e = ak.flatten(Za_2e)\n",
    "            Zb_e = ak.flatten(Zb_2e)\n",
    "\n",
    "            # mass requirement\n",
    "            M_Za_e = (((Za_e[\"0\"]+Za_e[\"1\"]).mass>40)&((Za_e[\"0\"]+Za_e[\"1\"]).mass<120))\n",
    "            M_Zb_e = (((Zb_e[\"0\"]+Zb_e[\"1\"]).mass>12)&((Zb_e[\"0\"]+Zb_e[\"1\"]).mass<120))\n",
    "\n",
    "            # transverse momentum requirement\n",
    "            pt_Z_e = (Za_e[\"0\"].pt>20)&(Za_e[\"1\"].pt>10)\n",
    "\n",
    "            # applying the cuts to get the good Z bosons\n",
    "            good_Za_e = Za_e[pt_Z_e&M_Za_e&M_Zb_e]\n",
    "            good_Zb_e = Zb_e[pt_Z_e&M_Za_e&M_Zb_e]\n",
    "\n",
    "            # Adding the pair of Z bosons that decayed to 4 electrons\n",
    "            higgs4e = good_Za_e[\"0\"]+good_Za_e[\"1\"] + good_Zb_e[\"0\"]+good_Zb_e[\"1\"]\n",
    "\n",
    "            # applying a mass range\n",
    "            Higgs_4e = higgs4e[higgs4e.mass>70]\n",
    "\n",
    "            mass_hist.fill(\n",
    "                mass=Higgs_4e.mass,\n",
    "                channel='4e',\n",
    "                dataset=dataset\n",
    "            )\n",
    "\n",
    "        ### Higgs to 4 electrons end ###\n",
    "        \n",
    "        ### Higgs to 2 muons, 2 electrons starts ###\n",
    "\n",
    "        # two objects cut\n",
    "        two_and_two = (ak.num(good_mu)>=2) & (ak.num(good_e)>=2)\n",
    "\n",
    "        # entries with two objects\n",
    "        twomuons = good_mu[ two_and_two ]\n",
    "        twoelect = good_e[ two_and_two ]\n",
    "\n",
    "        if (len(twomuons) > 0) and (len(twoelect) > 0):\n",
    "            \n",
    "            # sort from highest to lowest transverse momentum\n",
    "            twomuons_sorted = twomuons[ak.argsort(twomuons.pt, axis=-1, ascending=False)]\n",
    "\n",
    "            twoelect_sorted = twoelect[ak.argsort(twoelect.pt, axis=-1, ascending=False)]\n",
    "\n",
    "            # first and second muons\n",
    "            mu1 = twomuons_sorted[:,0]\n",
    "            mu2 = twomuons_sorted[:,1]\n",
    "\n",
    "            # first and second electrons\n",
    "            e1 = twoelect_sorted[:,0]\n",
    "            e2 = twoelect_sorted[:,1]\n",
    "\n",
    "            ## \n",
    "            charge_cut = (mu1.charge + mu2.charge ==0) & (e1.charge + e2.charge ==0)\n",
    "            ##\n",
    "\n",
    "            # Z boson from muon pairs\n",
    "            Z_mu = mu1+mu2\n",
    "\n",
    "            # Z boson from electron pairs\n",
    "            Z_e = e1+e2\n",
    "\n",
    "            # real Z boson and Z_mu mass difference\n",
    "            dZmu = abs(Z_mu.mass - mZ)\n",
    "\n",
    "            # real Z boson and Z_e mass difference\n",
    "            dZe = abs(Z_e.mass - mZ)\n",
    "\n",
    "            ## condition to test which pair's mass is closer to the Z boson's mass\n",
    "            mu_is_closer = dZmu < dZe\n",
    "\n",
    "            ptZadaug = (mu_is_closer & ((mu1.pt > 20) & (mu2.pt > 10))) | (~mu_is_closer & ((e1.pt > 20) & (e2.pt > 10)))\n",
    "            ##\n",
    "\n",
    "            # closest pair to the Z boson (Za)\n",
    "            eZa = np.where(mu_is_closer, Z_mu.energy, Z_e.energy)\n",
    "            pxZa = np.where(mu_is_closer, Z_mu.px, Z_e.px)\n",
    "            pyZa = np.where(mu_is_closer, Z_mu.py, Z_e.py)\n",
    "            pzZa = np.where(mu_is_closer, Z_mu.pz, Z_e.pz)\n",
    "            pTZa = np.where(mu_is_closer, Z_mu.pt, Z_e.pt)\n",
    "            mZa = np.where(mu_is_closer, Z_mu.mass, Z_e.mass)\n",
    "\n",
    "            # farthest pair to the Z boson (Zb)\n",
    "            eZb = np.where(mu_is_closer, Z_e.energy, Z_mu.energy)\n",
    "            pxZb = np.where(mu_is_closer, Z_e.px, Z_mu.px)\n",
    "            pyZb = np.where(mu_is_closer, Z_e.py, Z_mu.py)\n",
    "            pzZb = np.where(mu_is_closer, Z_e.pz, Z_mu.pz)\n",
    "            pTZb = np.where(mu_is_closer, Z_e.pt, Z_mu.pt)\n",
    "            mZb = np.where(mu_is_closer, Z_e.mass, Z_mu.mass)\n",
    "\n",
    "            ## \n",
    "            mass_cut = ( (ptZadaug) & ((mZa>40)&(mZa<120)) & ((mZb>12)&(mZb<120)) )\n",
    "            ##\n",
    "\n",
    "            ## calculating the Higgs from the sum of Za and Zb\n",
    "            # energy\n",
    "            H_en = Z_mu.energy + Z_e.energy\n",
    "\n",
    "            # momentum\n",
    "            H_px = Z_mu.px + Z_e.px\n",
    "            H_py = Z_mu.py + Z_e.py\n",
    "            H_pz = Z_mu.pz + Z_e.pz\n",
    "\n",
    "            # momentum's magnitude\n",
    "            H_P = np.sqrt(H_px**2 + H_py**2 + H_pz**2)\n",
    "\n",
    "            # invariant mass\n",
    "            H_M = np.sqrt(H_en**2 - H_P**2)\n",
    "\n",
    "            # applying the charge and mass cuts\n",
    "            higgs2mu2e = H_M[ charge_cut & mass_cut]\n",
    "\n",
    "            # applying a mass range\n",
    "            Higgs_2mu2e = higgs2mu2e[higgs2mu2e>70]\n",
    "\n",
    "            mass_hist.fill(\n",
    "                mass=Higgs_2mu2e,\n",
    "                channel='2e2m',\n",
    "                dataset=dataset\n",
    "            )\n",
    "\n",
    "        ### Higgs to 2 muons, 2 electrons ends ###\n",
    "        \n",
    "        return {\n",
    "            \"sumw\": sumw,\n",
    "            \"mass\": mass_hist,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40403dc4-c298-4c04-a9db-e0ce5425177d",
   "metadata": {},
   "source": [
    "# Run on a MC File\n",
    "\n",
    "Again, we will run on a CMS Higgs MC sample to demonstrate this all works before unleashing it on all the data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2793ea0-beb9-4e4f-9875-3cda954bea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(name: str, query: ObjectStream):\n",
    "    '''Create a ServiceX Datasource for a particular ATLAS Open data file\n",
    "    '''\n",
    "    from utils import cms_files\n",
    "    datasets = [ServiceXDataset(cms_files[name]['files'], backend_name='cms_run1_aod')]\n",
    "    return DataSource(query=query, metadata={'dataset': name, 'is_data': False}, datasets=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e54cbf8c-76a9-40b0-a1c5-e8884767b657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_2e_7TeV, data_2mu_7TeV, data_2mu_8TeV_B, data_2mu_8TeV_C, data_2e_8TeV_B, data_2e_8TeV_C, SMHiggsToZZTo4L_M_125_7TeV, SMHiggsToZZTo4L_M-125_8TeV, ZZTo4mu_mll4_7TeV, ZZTo4e_mll4_7TeV_II, ZZTo2e2mu_mll4_7TeV, DYJetsToLL_M-50_7TeV, DYJetsToLL_M-10To50_TuneZ2_7TeV, DYJetsToLL_M-50_TuneZ2Star_8TeV, DYJetsToLL_M-10to50_HT-200to400_TuneZ2star_8TeV, DYJetsToLL_M-10to50_HT-400toInf_TuneZ2star_8TeV, TTTo2L2Nu2B_7TeV, ZZTo4mu_8TeV, ZZTo4e_8TeV, ZZTo2e2mu_8TeV, TTbar_8TeV'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import cms_files\n",
    "all_datasets = list(cms_files.keys())\n",
    "', '.join(all_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226cc35b-6829-47f5-8bbc-6b9397bbcc08",
   "metadata": {},
   "source": [
    "The routine that will run on multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa7eeae3-167d-488a-89e6-d77d0eab770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_analysis(names: List[str]):\n",
    "    'Generate base plot for a multiple datafiles'\n",
    "\n",
    "    executor = LocalExecutor()\n",
    "    #executor = DaskExecutor(client_addr=\"tls://localhost:8786\")\n",
    "    print(executor)\n",
    "    datasources = [make_ds(ds_name, cms_selection) for ds_name in names]\n",
    "\n",
    "    # Create the analysis and we can run from there.\n",
    "    analysis = CMS_Higgs_4L()\n",
    "\n",
    "    async def run_updates_stream(accumulator_stream, name):\n",
    "        '''Run to get the last item in the stream, with a useful error message'''\n",
    "        coffea_info = None\n",
    "        try:\n",
    "            async for coffea_info in accumulator_stream:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Failure while processing {name}') from e\n",
    "        return coffea_info\n",
    "\n",
    "    # Run on all items and wait till they are done!\n",
    "    all_plots = await asyncio.gather(*[run_updates_stream(executor.execute(analysis, source), source.metadata['dataset']) for source in datasources])\n",
    "    \n",
    "    all_plots_mass = [p['mass'] for p in all_plots]\n",
    "    mass = all_plots_mass[0]\n",
    "    for p in all_plots_mass[1:]:\n",
    "        mass += p\n",
    "\n",
    "    return mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a0acb4a-8a56-4d30-ad28-e7966ed22b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<coffea.processor.servicex.local_executor.LocalExecutor object at 0x7faf4d5cf790>\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failure while processing SMHiggsToZZTo4L_M_125_7TeV",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceXException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4140/1967275335.py\u001b[0m in \u001b[0;36mrun_updates_stream\u001b[0;34m(accumulator_stream, name)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcoffea_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccumulator_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/servicex/executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, analysis, datasource, title)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mfinished_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstreamer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0masync_accumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/accumulator.py\u001b[0m in \u001b[0;36masync_accumulate\u001b[0;34m(result_stream)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/aiostream/stream/advanced.py\u001b[0m in \u001b[0;36mbase_combine\u001b[0;34m(source, switch, ordered, task_limit)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/aiostream/stream/combine.py\u001b[0m in \u001b[0;36msmap\u001b[0;34m(source, func, *more_sources)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mstreamcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstreamer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstreamer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmore_sources\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/servicex/executor.py\u001b[0m in \u001b[0;36mlaunch_analysis_tasks_from_stream\u001b[0;34m(self, result_file_stream, meta_data, process_func)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mtree_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msx_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_file_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mfile_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msx_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/servicex/data_source.py\u001b[0m in \u001b[0;36mstream_result_files\u001b[0;34m(self, title)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"root\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 async for file in dataset.get_data_rootfiles_stream(\n\u001b[0m\u001b[1;32m    107\u001b[0m                     \u001b[0mqastle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/servicex/servicex.py\u001b[0m in \u001b[0;36mget_data_rootfiles_stream\u001b[0;34m(self, selection_query, title)\u001b[0m\n\u001b[1;32m    293\u001b[0m         '''\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf_info\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream_local_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'root-files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/servicex/servicex.py\u001b[0m in \u001b[0;36m_stream_local_files\u001b[0;34m(self, selection_query, title, data_format)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mas_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mStreamInfoPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0ma_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/servicex/servicex.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mas_files\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             (f async for f in\n\u001b[0m\u001b[1;32m    596\u001b[0m              self._get_files(selection_query, data_format, notifier, title))  # type: ignore\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/servicex/servicex.py\u001b[0m in \u001b[0;36m_get_files\u001b[0;34m(self, selection_query, data_type, notifier, title)\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0;31m# Get a request id - which might be cached, but if not, submit it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_request_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/servicex/servicex.py\u001b[0m in \u001b[0;36m_get_request_id\u001b[0;34m(self, client, query)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequest_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mrequest_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_servicex_adaptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m             \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'request_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/servicex/servicex_adaptor.py\u001b[0m in \u001b[0;36msubmit_query\u001b[0;34m(self, client, json_query)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 raise ServiceXException('ServiceX rejected the transformation request: '\n\u001b[0m\u001b[1;32m     67\u001b[0m                                         f'({status}){t}')\n",
      "\u001b[0;31mServiceXException\u001b[0m: (ServiceXException(...), 'ServiceX rejected the transformation request: (400){\"message\": \"Failed to submit transform request: Failed to generate translation code: Unknown id: ResultTTree\"}\\n')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4140/1252709367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmc_mass_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mrun_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SMHiggsToZZTo4L_M_125_7TeV'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4140/1967275335.py\u001b[0m in \u001b[0;36mrun_analysis\u001b[0;34m(names)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Run on all items and wait till they are done!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mall_plots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_updates_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasources\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mall_plots_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mass'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_plots\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4140/1967275335.py\u001b[0m in \u001b[0;36mrun_updates_stream\u001b[0;34m(accumulator_stream, name)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Failure while processing {name}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcoffea_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Failure while processing SMHiggsToZZTo4L_M_125_7TeV"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "mc_mass_plot = await run_analysis(['SMHiggsToZZTo4L_M_125_7TeV'])\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b075eb3-1f20-4326-bd7f-7af4a0082f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "artists = mc_mass_plot.project('mass', 'channel').plot(stack=True)\n",
    "ax = artists[0].stairs.axes  # get the axis\n",
    "ax.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ce242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
